import streamlit as st
import os
import tempfile
from dotenv import load_dotenv
import subprocess
import wave
import numpy as np
from audio_recorder_streamlit import audio_recorder

# å°å…¥ç¾æœ‰çš„æ¨¡çµ„
from utils.watson_assistant import WatsonAssistant
from utils.text_to_speech import TextToSpeech
from utils.hardware_control import HardwareControl
from ibm_watson import SpeechToTextV1
from ibm_cloud_sdk_core.authenticators import IAMAuthenticator

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# è¨­å®š Streamlit é é¢é…ç½®
st.set_page_config(
    page_title="TJBot Controller",
    page_icon="ğŸ¤–",
    layout="wide"
)

# åˆå§‹åŒ– Session State
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'assistant' not in st.session_state:
    st.session_state.assistant = None
if 'tts' not in st.session_state:
    st.session_state.tts = None
if 'stt' not in st.session_state:
    st.session_state.stt = None
if 'hardware' not in st.session_state:
    st.session_state.hardware = None
if 'initialization_status' not in st.session_state:
    st.session_state.initialization_status = "æœªåˆå§‹åŒ–"

class SpeechToText:
    def __init__(self, apikey, url):
        authenticator = IAMAuthenticator(apikey)
        self.speech_to_text = SpeechToTextV1(authenticator=authenticator)
        self.speech_to_text.set_service_url(url)

    def recognize_audio(self, audio_data, content_type='audio/webm'):
        """è­˜åˆ¥éŸ³è¨Šæª”æ¡ˆ"""
        try:
            result = self.speech_to_text.recognize(
                audio=audio_data,
                content_type=content_type,
                model='en-US_BroadbandModel',
            ).get_result()

            if 'results' in result and len(result['results']) > 0:
                transcript = result['results'][0]['alternatives'][0]['transcript']
                return transcript
            else:
                return ""
        except Exception as e:
            st.error(f"èªéŸ³è­˜åˆ¥éŒ¯èª¤: {e}")
            return ""

def convert_webm_to_wav(webm_data):
    """å°‡ webm éŸ³é »è½‰æ›ç‚º wav æ ¼å¼"""
    with tempfile.NamedTemporaryFile(suffix='.webm', delete=False) as temp_webm:
        temp_webm.write(webm_data)
        webm_path = temp_webm.name
    
    wav_path = webm_path.replace('.webm', '.wav')
    try:
        # ä½¿ç”¨ ffmpeg è½‰æ›æ ¼å¼ï¼ˆç¢ºä¿å·²å®‰è£ï¼‰
        subprocess.run(['ffmpeg', '-i', webm_path, '-ac', '1', '-ar', '16000', wav_path], 
                      check=True, capture_output=True)
        
        with open(wav_path, 'rb') as wav_file:
            wav_data = wav_file.read()
        
        # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
        os.unlink(webm_path)
        os.unlink(wav_path)
        
        return wav_data
    except subprocess.CalledProcessError as e:
        st.error(f"éŸ³é »è½‰æ›å¤±æ•—: {e}")
        os.unlink(webm_path)
        return None

def initialize_components():
    """åˆå§‹åŒ–æ‰€æœ‰å…ƒä»¶"""
    try:
        # åˆå§‹åŒ– Watson Assistant
        st.session_state.assistant = WatsonAssistant(
            os.getenv('ASSISTANT_APIKEY'),
            os.getenv('ASSISTANT_URL'),
            os.getenv('ASSISTANT_ID'),
            version='2023-04-15'
        )
        
        # åˆå§‹åŒ– Text to Speech
        st.session_state.tts = TextToSpeech(
            os.getenv('TTS_APIKEY'),
            os.getenv('TTS_URL')
        )
        
        # åˆå§‹åŒ– Speech to Text
        st.session_state.stt = SpeechToText(
            os.getenv('STT_APIKEY'),
            os.getenv('STT_URL')
        )
        
        # åˆå§‹åŒ–ç¡¬é«”æ§åˆ¶
        st.session_state.hardware = HardwareControl()
        
        st.session_state.initialization_status = "å·²åˆå§‹åŒ–"
        return True
    except Exception as e:
        st.session_state.initialization_status = f"åˆå§‹åŒ–å¤±æ•—: {str(e)}"
        return False

def process_message(user_input):
    """è™•ç†ä½¿ç”¨è€…è¨Šæ¯ä¸¦åŸ·è¡Œç›¸æ‡‰å‹•ä½œ"""
    if not st.session_state.assistant:
        st.error("æœå‹™å°šæœªåˆå§‹åŒ–ï¼")
        return
    
    # ç™¼é€åˆ° Watson Assistant
    response = st.session_state.assistant.send_message(user_input)
    
    if response:
        # è™•ç†å›æ‡‰
        intents = response.get('output', {}).get('intents', [])
        entities = response.get('output', {}).get('entities', [])
        response_texts = response.get('output', {}).get('generic', [])
        
        # é¡¯ç¤ºå›æ‡‰
        bot_reply = ""
        for text in response_texts:
            if text['response_type'] == 'text':
                bot_reply += text['text'] + " "
        
        # ä¿å­˜å°è©±æ­·å²
        st.session_state.chat_history.append(("ä½¿ç”¨è€…", user_input))
        st.session_state.chat_history.append(("TJBot", bot_reply))
        
        # åŸ·è¡Œç¡¬é«”å‹•ä½œ
        if intents:
            top_intent = intents[0]['intent']
            if top_intent == 'wave':
                st.session_state.hardware.wave()
                st.info("æ©Ÿå™¨äººæ®æ‰‹ğŸ‘‹")
            elif top_intent == 'lower-arm':
                st.session_state.hardware.lower_arm()
                st.info("æ©Ÿå™¨äººæ”¾ä¸‹æ‰‹è‡‚ğŸ™‡")
            elif top_intent == 'raise-arm':
                st.session_state.hardware.raise_arm()
                st.info("æ©Ÿå™¨äººèˆ‰èµ·æ‰‹è‡‚ğŸ™‹â€â™‚ï¸")
            elif top_intent == 'shine':
                color = next((e['value'] for e in entities if e['entity'] == 'color'), 'white')
                st.session_state.hardware.shine(color)
                st.info(f"æ©Ÿå™¨äººç™¼å…‰: {color}âœ¨")
        
        # èªéŸ³è¼¸å‡ºï¼ˆä½¿ç”¨ç¾æœ‰çš„ text_to_speechï¼‰
        if st.session_state.tts and bot_reply:
            with st.spinner("æ­£åœ¨åˆæˆèªéŸ³..."):
                # ä½¿ç”¨ä½ ç¾æœ‰çš„ text_to_speech.py ä¸­çš„ speak æ–¹æ³•
                st.session_state.tts.speak(bot_reply)
                
                # ç”±æ–¼ speak æ–¹æ³•æœƒå»ºç«‹ response.wavï¼Œæˆ‘å€‘å¯ä»¥æä¾›çµ¦å‰ç«¯æ’­æ”¾
                if os.path.exists('response.wav'):
                    st.audio('response.wav', format='audio/wav')
        
        return bot_reply
    else:
        st.error("ç„¡æ³•ç²å– Watson å›æ‡‰")
        return None

# ä¸»è¦ä»‹é¢
st.title("ğŸ¤– TJBot Controller")
st.write("é€éæ–‡å­—æˆ–èªéŸ³èˆ‡ TJBot äº’å‹•")

# å´é‚Šæ¬„ - ç‹€æ…‹å’Œæ§åˆ¶
with st.sidebar:
    st.header("ç³»çµ±ç‹€æ…‹")
    
    # åˆå§‹åŒ–æŒ‰éˆ•
    if st.button("åˆå§‹åŒ–ç³»çµ±"):
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–..."):
            if initialize_components():
                st.success("ç³»çµ±åˆå§‹åŒ–æˆåŠŸï¼")
            else:
                st.error("ç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼")
    
    st.write(f"ç‹€æ…‹: {st.session_state.initialization_status}")
    
    # æ‰‹å‹•ç¡¬é«”æ§åˆ¶
    st.header("æ‰‹å‹•æ§åˆ¶")
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ‘‹ æ®æ‰‹"):
            if st.session_state.hardware:
                st.session_state.hardware.wave()
            else:
                st.error("ç¡¬é«”æœªåˆå§‹åŒ–")
        
        if st.button("ğŸ™‹â€â™‚ï¸ èˆ‰æ‰‹"):
            if st.session_state.hardware:
                st.session_state.hardware.raise_arm()
            else:
                st.error("ç¡¬é«”æœªåˆå§‹åŒ–")
    
    with col2:
        if st.button("ğŸ™‡ æ”¾ä¸‹æ‰‹"):
            if st.session_state.hardware:
                st.session_state.hardware.lower_arm()
            else:
                st.error("ç¡¬é«”æœªåˆå§‹åŒ–")
        
        color = st.selectbox("LED é¡è‰²", ["red", "green", "blue", "white"])
        if st.button("ğŸ’¡ é»äº®"):
            if st.session_state.hardware:
                st.session_state.hardware.shine(color)
            else:
                st.error("ç¡¬é«”æœªåˆå§‹åŒ–")

# ä¸»è¦å€åŸŸ - èŠå¤©ä»‹é¢
st.header("å°è©±å€åŸŸ")

# é¡¯ç¤ºèŠå¤©æ­·å²
for role, message in st.session_state.chat_history:
    if role == "ä½¿ç”¨è€…":
        st.chat_message("user").write(message)
    else:
        st.chat_message("assistant").write(message)

# è¼¸å…¥æ–¹å¼é¸æ“‡
input_mode = st.radio("é¸æ“‡è¼¸å…¥æ–¹å¼", ["æ–‡å­—", "èªéŸ³"])

if input_mode == "æ–‡å­—":
    # æ–‡å­—è¼¸å…¥
    user_input = st.chat_input("è«‹è¼¸å…¥è¨Šæ¯...")
    
    if user_input:
        st.chat_message("user").write(user_input)
        with st.spinner("è™•ç†ä¸­..."):
            process_message(user_input)
else:
    # èªéŸ³è¼¸å…¥
    st.write("é»æ“Šä¸‹æ–¹æŒ‰éˆ•é–‹å§‹éŒ„éŸ³ï¼š")
    
    audio_bytes = audio_recorder(
        text="é»æ“ŠéŒ„éŸ³",
        recording_color="#e8b62c",
        neutral_color="#6aa36f",
        icon_name="microphone",
        icon_size="4x",
    )
    
    if audio_bytes and st.session_state.stt:
        with st.spinner("æ­£åœ¨è­˜åˆ¥èªéŸ³..."):
            # è½‰æ›éŸ³é »æ ¼å¼
            wav_data = convert_webm_to_wav(audio_bytes)
            
            if wav_data:
                # é€²è¡ŒèªéŸ³è­˜åˆ¥
                user_input = st.session_state.stt.recognize_audio(wav_data, content_type='audio/wav')
                
                if user_input:
                    st.chat_message("user").write(user_input)
                    with st.spinner("è™•ç†ä¸­..."):
                        process_message(user_input)
                else:
                    st.error("ç„¡æ³•è­˜åˆ¥èªéŸ³ï¼Œè«‹å†è©¦ä¸€æ¬¡")
            else:
                st.error("éŸ³é »æ ¼å¼è½‰æ›å¤±æ•—")

# é è…³
st.markdown("---")
st.markdown("TJBot Controller - powered by IBM Watson AI")